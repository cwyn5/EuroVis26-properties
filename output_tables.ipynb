{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890aaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8436aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vertical(df, score_name):\n",
    "    if df.shape[1] > df.shape[0]:\n",
    "        df = df.T\n",
    "    \n",
    "    if df.columns.size == 1:\n",
    "        df.columns = [score_name]\n",
    "    \n",
    "    df.index.name = 'Property'\n",
    "    df_clean = df.dropna()\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3e27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ICC Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICC_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intuition-building</th>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearly Articulated</th>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credible</th>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoped</th>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact</th>\n",
       "      <td>-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strictness</th>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actionable</th>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discoverable</th>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updateable</th>\n",
       "      <td>-0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permanence</th>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ICC_Score\n",
       "Property                      \n",
       "Intuition-building       0.243\n",
       "Clearly Articulated      0.185\n",
       "Credible                 0.832\n",
       "Scoped                   0.458\n",
       "Impact                  -0.039\n",
       "Strictness               0.158\n",
       "Actionable               0.526\n",
       "Discoverable             0.340\n",
       "Relationships            0.556\n",
       "Updateable              -0.159\n",
       "Permanence               0.535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_icc_raw = pd.read_csv('output_icc.csv')\n",
    "df_icc_vertical = make_vertical(df_icc_raw, 'ICC_Score')\n",
    "\n",
    "print(\"--- ICC Results ---\")\n",
    "display(df_icc_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc575321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Weighted Kappa Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weighted_Kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intuition-building</th>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearly Articulated</th>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credible</th>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoped</th>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact</th>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strictness</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actionable</th>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discoverable</th>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updateable</th>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permanence</th>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Weighted_Kappa\n",
       "Property                           \n",
       "Intuition-building            0.337\n",
       "Clearly Articulated           0.322\n",
       "Credible                      0.746\n",
       "Scoped                        0.383\n",
       "Impact                       -0.053\n",
       "Strictness                    0.235\n",
       "Actionable                    0.562\n",
       "Discoverable                  0.374\n",
       "Relationships                 0.496\n",
       "Updateable                   -0.070\n",
       "Permanence                    0.504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kappa_raw = pd.read_csv('output_kappa.csv', index_col=0)\n",
    "df_kappa_vertical = make_vertical(df_kappa_raw, 'Weighted_Kappa')\n",
    "\n",
    "print(\"--- Weighted Kappa Results ---\")\n",
    "display(df_kappa_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38489779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparison Table ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICC_Score</th>\n",
       "      <th>Weighted_Kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actionable</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clearly Articulated</th>\n",
       "      <td>0.185</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credible</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discoverable</th>\n",
       "      <td>0.340</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Impact</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intuition-building</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permanence</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relationships</th>\n",
       "      <td>0.556</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scoped</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strictness</th>\n",
       "      <td>0.158</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updateable</th>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ICC_Score  Weighted_Kappa\n",
       "Property                                      \n",
       "Actionable               0.526           0.562\n",
       "Clearly Articulated      0.185           0.322\n",
       "Credible                 0.832           0.746\n",
       "Discoverable             0.340           0.374\n",
       "Impact                  -0.039          -0.053\n",
       "Intuition-building       0.243           0.337\n",
       "Permanence               0.535           0.504\n",
       "Relationships            0.556           0.496\n",
       "Scoped                   0.458           0.383\n",
       "Strictness               0.158           0.235\n",
       "Updateable              -0.159          -0.070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison = df_icc_vertical.join(df_kappa_vertical, how='outer')\n",
    "    \n",
    "print(\"--- Comparison Table ---\")\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a5436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_by_source(filename, coder_name):\n",
    "    df = pd.read_excel(filename)\n",
    "    doc_ids = [str(col).strip() for col in df.columns if \"Document ID\" not in str(col)]\n",
    "    \n",
    "    sources = [doc_id[0].upper() for doc_id in doc_ids]\n",
    "    \n",
    "    counts = pd.Series(sources).value_counts()\n",
    "    return counts, set(doc_ids)\n",
    "\n",
    "sophie_counts, sophie_ids = get_counts_by_source(\"Validation Study_Sophie.xlsx\", \"Sophie\")\n",
    "cat_counts, cat_ids = get_counts_by_source(\"CN_processed.xlsx\", \"CN\")\n",
    "\n",
    "all_unique_ids = sophie_ids.union(cat_ids)\n",
    "all_sources = [doc_id[0].upper() for doc_id in all_unique_ids]\n",
    "total_counts = pd.Series(all_sources).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d6798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Coding Progress by Source Type ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Available</th>\n",
       "      <th>Sophie Coded</th>\n",
       "      <th>Cat Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIS Papers</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crowdsourced</th>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Web Blogs</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total Available  Sophie Coded  Cat Coded\n",
       "VIS Papers                 28            27         27\n",
       "Books                      30            10         30\n",
       "Crowdsourced               18            16         16\n",
       "Web Blogs                  20            20          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_map = {\n",
    "    'V': 'VIS Papers',\n",
    "    'B': 'Books',\n",
    "    'C': 'Crowdsourced',\n",
    "    'W': 'Web Blogs'\n",
    "}\n",
    "\n",
    "summary_table = pd.DataFrame({\n",
    "    'Total Available': total_counts,\n",
    "    'Sophie Coded': sophie_counts,\n",
    "    'Cat Coded': cat_counts\n",
    "})\n",
    "\n",
    "summary_table = summary_table.fillna(0).astype(int)\n",
    "\n",
    "summary_table.index = summary_table.index.map(name_map)\n",
    "\n",
    "desired_order = ['VIS Papers', 'Books', 'Crowdsourced', 'Web Blogs']\n",
    "existing_order = [x for x in desired_order if x in summary_table.index]\n",
    "summary_table = summary_table.loc[existing_order]\n",
    "\n",
    "# Display\n",
    "from IPython.display import display\n",
    "print(\"--- Coding Progress by Source Type ---\")\n",
    "display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Mismatch Report ---\n",
      "IDs in Sophie's file but NOT in Cat's (23):\n",
      "['CS-10 : VG-GL-12', 'CS-4 : VG-GL-4', 'VIS-6 : VIS-GL-15', 'WB-1 : WB-GL-1', 'WB-10 : WB-GL-10', 'WB-11 : WB-GL-11', 'WB-11 : WB-GL-12', 'WB-11 : WB-GL-13', 'WB-11 : WB-GL-14', 'WB-12 : WB-GL-15', 'WB-13 : WB-GL-16', 'WB-14 : WB-GL-17', 'WB-15 : WB-GL-18', 'WB-16 : WB-GL-19', 'WB-17 : WB-GL-20', 'WB-2 : WB-GL-2', 'WB-3 : WB-GL-3', 'WB-4 : WB-GL-4', 'WB-5 : WB-GL-5', 'WB-6 : WB-GL-6', 'WB-7 : WB-GL-7', 'WB-8 : WB-GL-8', 'WB-9 : WB-GL-9']\n",
      "\n",
      "IDs in Cat's file but NOT in Sophie's (23):\n",
      "['BK-2 : BK-GL-11', 'BK-2 : BK-GL-12', 'BK-2 : BK-GL-13', 'BK-2 : BK-GL-14', 'BK-2 : BK-GL-15', 'BK-2 : BK-GL-16', 'BK-2 : BK-GL-17', 'BK-2 : BK-GL-18', 'BK-2 : BK-GL-19', 'BK-3 : BK-GL-20', 'BK-3 : BK-GL-21', 'BK-3 : BK-GL-22', 'BK-3 : BK-GL-23', 'BK-3 : BK-GL-24', 'BK-3 : BK-GL-25', 'BK-3 : BK-GL-26', 'BK-3 : BK-GL-27', 'BK-3 : BK-GL-28', 'BK-3 : BK-GL-29', 'BK-3 : BK-GL-30', 'CS-11 : VG-GL-12', 'CS-4 : VS-GL-4', 'VIS-6: VIS-GL-15']\n"
     ]
    }
   ],
   "source": [
    "def get_ids(filename):\n",
    "    try:\n",
    "        df = pd.read_excel(filename)\n",
    "        return set([str(col).strip() for col in df.columns if \"Document ID\" not in str(col)])\n",
    "    except FileNotFoundError:\n",
    "        return set()\n",
    "\n",
    "sophie_ids = get_ids(\"Validation Study_Sophie.xlsx\")\n",
    "cat_ids = get_ids(\"CN_processed.xlsx\")\n",
    "\n",
    "only_in_sophie = sophie_ids - cat_ids\n",
    "only_in_cat = cat_ids - sophie_ids\n",
    "\n",
    "print(f\"--- Mismatch Report ---\")\n",
    "print(f\"IDs in Sophie's file but NOT in Cat's ({len(only_in_sophie)}):\")\n",
    "print(sorted(list(only_in_sophie)))\n",
    "\n",
    "print(f\"\\nIDs in Cat's file but NOT in Sophie's ({len(only_in_cat)}):\")\n",
    "print(sorted(list(only_in_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4232238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Coding Progress by Source Type ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Available</th>\n",
       "      <th>Sophie Coded</th>\n",
       "      <th>Cat Coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIS Papers</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crowdsourced</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Web Blogs</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total Available  Sophie Coded  Cat Coded\n",
       "VIS Papers                 27            27         27\n",
       "Books                      30            10         30\n",
       "Crowdsourced               16            16         16\n",
       "Web Blogs                  20            20          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Hard Coded for now until we fix that\n",
    "\n",
    "data = {\n",
    "    'Total Available': [27, 30, 16, 20],\n",
    "    'Sophie Coded':    [27, 10, 16, 20],\n",
    "    'Cat Coded':       [27, 30, 16, 0]\n",
    "}\n",
    "\n",
    "index_labels = ['VIS Papers', 'Books', 'Crowdsourced', 'Web Blogs']\n",
    "summary_table = pd.DataFrame(data, index=index_labels)\n",
    "\n",
    "print(\"--- Coding Progress by Source Type ---\")\n",
    "display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc286014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying corrections...\n",
      "✅ Success: Found 'CS-10 : VG-GL-12'\n",
      "✅ Success: Found 'CS-4 : VG-GL-4'\n",
      "✅ Success: Found 'VIS-6 : VIS-GL-15'\n",
      "\n",
      "Saved corrected file to: CN_processed_FIXED.xlsx\n"
     ]
    }
   ],
   "source": [
    "cat_file_path = \"CN_processed.xlsx\"\n",
    "df_cat = pd.read_excel(cat_file_path)\n",
    "\n",
    "corrections = {\n",
    "    'CS-11 : VG-GL-12': 'CS-10 : VG-GL-12',\n",
    "    'CS-4 : VS-GL-4':   'CS-4 : VG-GL-4',\n",
    "    'VIS-6: VIS-GL-15': 'VIS-6 : VIS-GL-15' \n",
    "}\n",
    "\n",
    "df_cat.rename(columns=corrections, inplace=True)\n",
    "\n",
    "print(\"Verifying corrections...\")\n",
    "for old, new in corrections.items():\n",
    "    if new in df_cat.columns:\n",
    "        print(f\"✅ Success: Found '{new}'\")\n",
    "    else:\n",
    "        print(f\"❌ Warning: Did not find '{new}' (Maybe it was already fixed?)\")\n",
    "\n",
    "new_filename = \"CN_processed_FIXED.xlsx\"\n",
    "df_cat.to_excel(new_filename, index=False)\n",
    "print(f\"\\nSaved corrected file to: {new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129033d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inter-Rater Reliability: Binary Elements ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohen's Kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Element (Yes/No)</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Example Present</th>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Counter-example Present</th>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slogan Present</th>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action Present</th>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Cohen's Kappa\n",
       "Element (Yes/No)                      \n",
       "Example Present                  0.240\n",
       "Counter-example Present          0.313\n",
       "Slogan Present                   0.481\n",
       "Action Present                   0.411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_elements = pd.read_csv('output_elements_kappa.csv', index_col=0)\n",
    "df_elements.index.name = 'Element (Yes/No)'\n",
    "df_elements.columns = ['Cohen\\'s Kappa']\n",
    "\n",
    "print(\"--- Inter-Rater Reliability: Binary Elements ---\")\n",
    "\n",
    "display(df_elements.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "add15979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Property                       | % Agree    | Both Y   | Both N   | Sophie Y/Cat N  | Sophie N/Cat Y \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Example Present                | 60.4%      | 16       | 16       | 16              | 5              \n",
      "Counter-example Present        | 71.7%      | 7        | 31       | 12              | 3              \n",
      "Action Present                 | 84.9%      | 41       | 4        | 4               | 4              \n",
      "Slogan Present                 | 73.6%      | 16       | 23       | 12              | 2              \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# 1. Load Data (Ensure you use the FIXED file for Cat)\n",
    "r1 = pd.read_excel(\"Validation Study_Sophie.xlsx\")\n",
    "r2 = pd.read_excel(\"CN_processed_FIXED.xlsx\")\n",
    "\n",
    "# 2. Find Common Docs\n",
    "common_docs = r1.columns.intersection(r2.columns)\n",
    "\n",
    "# 3. Transpose and Clean\n",
    "def get_clean_df(df, common_cols):\n",
    "    df_T = df[common_cols].T\n",
    "    # Use first row as header\n",
    "    df_T.columns = df_T.iloc[0]\n",
    "    # Drop header row\n",
    "    df_T = df_T[1:]\n",
    "    # Clean column names (strip whitespace)\n",
    "    df_T.columns = df_T.columns.astype(str).str.strip()\n",
    "    return df_T\n",
    "\n",
    "df1 = get_clean_df(r1, common_docs)\n",
    "df2 = get_clean_df(r2, common_docs)\n",
    "\n",
    "# 4. Define Targets (Make sure these match your Excel exactly, case-sensitive)\n",
    "target_cols = [\n",
    "    \"Example Present\", \n",
    "    \"Counter-example Present\", \n",
    "    \"Action Present\", \n",
    "    \"Slogan Present\"\n",
    "]\n",
    "\n",
    "print(f\"{'Property':<30} | {'% Agree':<10} | {'Both Y':<8} | {'Both N':<8} | {'Sophie Y/Cat N':<15} | {'Sophie N/Cat Y':<15}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "found_any = False\n",
    "\n",
    "for label in target_cols:\n",
    "    if label in df1.columns:\n",
    "        found_any = True\n",
    "        \n",
    "        # Map Y/N to 1/0 safely\n",
    "        def safe_map(s):\n",
    "            return s.astype(str).str.strip().str.upper().map({\n",
    "                'Y': 1, 'YES': 1, 'N': 0, 'NO': 0\n",
    "            }).fillna(0)\n",
    "\n",
    "        s1 = safe_map(df1[label])\n",
    "        s2 = safe_map(df2[label])\n",
    "        \n",
    "        # Calculate Confusion Matrix components\n",
    "        # 1 = Yes, 0 = No\n",
    "        both_y = ((s1 == 1) & (s2 == 1)).sum()\n",
    "        both_n = ((s1 == 0) & (s2 == 0)).sum()\n",
    "        sophie_y_cat_n = ((s1 == 1) & (s2 == 0)).sum()\n",
    "        sophie_n_cat_y = ((s1 == 0) & (s2 == 1)).sum()\n",
    "        \n",
    "        total = len(s1)\n",
    "        agreement = (both_y + both_n) / total\n",
    "        \n",
    "        print(f\"{label:<30} | {agreement:.1%}      | {both_y:<8} | {both_n:<8} | {sophie_y_cat_n:<15} | {sophie_n_cat_y:<15}\")\n",
    "\n",
    "if not found_any:\n",
    "    print(\"\\nERROR: Still didn't find columns. Here are the available columns in Sophie's file:\")\n",
    "    print(df1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af580043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
